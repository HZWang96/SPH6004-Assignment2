{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>total_protein</th>\n",
       "      <th>calcium</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>sodium</th>\n",
       "      <th>chloride</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>...</th>\n",
       "      <th>ph</th>\n",
       "      <th>lactate</th>\n",
       "      <th>pt</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>sofa_respiration</th>\n",
       "      <th>sofa_coagulation</th>\n",
       "      <th>sofa_liver</th>\n",
       "      <th>sofa_cardiovascular</th>\n",
       "      <th>sofa_cns</th>\n",
       "      <th>sofa_renal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35715575</td>\n",
       "      <td>2148-12-27 18:15:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>137.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34483718</td>\n",
       "      <td>2118-01-04 03:58:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>129.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31826892</td>\n",
       "      <td>2163-03-10 19:59:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36154799</td>\n",
       "      <td>2131-12-02 19:14:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32732521</td>\n",
       "      <td>2116-08-12 12:45:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stay_id                charttime  total_protein  calcium  creatinine  \\\n",
       "0  35715575  2148-12-27 18:15:00.000            NaN      8.5         0.9   \n",
       "1  34483718  2118-01-04 03:58:00.000            NaN      8.2         0.8   \n",
       "2  31826892  2163-03-10 19:59:00.000            NaN      7.7         0.4   \n",
       "3  36154799  2131-12-02 19:14:00.000            NaN      NaN         NaN   \n",
       "4  32732521  2116-08-12 12:45:00.000            NaN      NaN         4.0   \n",
       "\n",
       "   glucose  sodium  chloride  heart_rate  sbp  ...  ph  lactate    pt  \\\n",
       "0    137.0   138.0     104.0         NaN  NaN  ... NaN      NaN   NaN   \n",
       "1    129.0   141.0     101.0         NaN  NaN  ... NaN      NaN  12.1   \n",
       "2    112.0   136.0      98.0         NaN  NaN  ... NaN      NaN   NaN   \n",
       "3      NaN     NaN       NaN         NaN  NaN  ... NaN      NaN   NaN   \n",
       "4    135.0   139.0     105.0         NaN  NaN  ... NaN      NaN   NaN   \n",
       "\n",
       "   urineoutput  sofa_respiration  sofa_coagulation  sofa_liver  \\\n",
       "0          NaN               NaN               NaN         NaN   \n",
       "1          NaN               NaN               NaN         NaN   \n",
       "2          NaN               NaN               NaN         NaN   \n",
       "3          NaN               NaN               NaN         NaN   \n",
       "4          NaN               NaN               NaN         NaN   \n",
       "\n",
       "   sofa_cardiovascular  sofa_cns  sofa_renal  \n",
       "0                  NaN       NaN         NaN  \n",
       "1                  NaN       NaN         NaN  \n",
       "2                  NaN       NaN         NaN  \n",
       "3                  NaN       NaN         NaN  \n",
       "4                  NaN       NaN         NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sph_dynamic.csv into a Pandas dataframe and display the first 5 rows of the data\n",
    "dynamic_data = pd.read_csv('data/sph_dynamic.csv')\n",
    "dynamic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stay_id                   0\n",
       "charttime                 0\n",
       "total_protein          6930\n",
       "calcium                 933\n",
       "creatinine              261\n",
       "glucose                 444\n",
       "sodium                  214\n",
       "chloride                241\n",
       "heart_rate             6833\n",
       "sbp                    6895\n",
       "dbp                    6895\n",
       "mbp                    6887\n",
       "resp_rate              6832\n",
       "temperature            6974\n",
       "hemoglobin             1179\n",
       "wbc                    1207\n",
       "alt                    3964\n",
       "ast                    3936\n",
       "alp                    3976\n",
       "bilirubin_total        3957\n",
       "bilirubin_direct       6808\n",
       "bilirubin_indirect     6812\n",
       "ph                     7004\n",
       "lactate                7012\n",
       "pt                     3068\n",
       "urineoutput            6942\n",
       "sofa_respiration       7005\n",
       "sofa_coagulation       7023\n",
       "sofa_liver             7023\n",
       "sofa_cardiovascular    6872\n",
       "sofa_cns               6979\n",
       "sofa_renal             7024\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of missing values in each column of the dynamic_data\n",
    "dynamic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns in dynamic_data with more than 80% of the values\n",
    "for col in dynamic_data.columns:\n",
    "    if dynamic_data[col].isnull().sum() > len(dynamic_data)*0.8:\n",
    "        del dynamic_data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stay_id               0\n",
       "charttime             0\n",
       "calcium             933\n",
       "creatinine          261\n",
       "glucose             444\n",
       "sodium              214\n",
       "chloride            241\n",
       "hemoglobin         1179\n",
       "wbc                1207\n",
       "alt                3964\n",
       "ast                3936\n",
       "alp                3976\n",
       "bilirubin_total    3957\n",
       "pt                 3068\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now check the number of missing values in each column of the dynamic_data again\n",
    "dynamic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/240455136.py:15: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  dynamic_data = dynamic_data.groupby('stay_id').apply(liver_categorize)\n"
     ]
    }
   ],
   "source": [
    "# ['alt','ast','alp','bilirubin_total','pt'] are liver function related test results\n",
    "# create a new binary column 'liver_function_test', True/1 means have ever taken liver function test\n",
    "liver_test_result = ['alt','ast','alp','bilirubin_total','pt']\n",
    "def liver_categorize(group):\n",
    "    flag = True\n",
    "    for i in liver_test_result:\n",
    "        if group[i].notnull().any():\n",
    "            flag = False\n",
    "    if flag:\n",
    "        group['liver_function_test'] = False\n",
    "    else:\n",
    "        group['liver_function_test'] = True\n",
    "    return group\n",
    "\n",
    "dynamic_data = dynamic_data.groupby('stay_id').apply(liver_categorize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that patients with no relevant results recorded do not have liver issues, we impute these patients' missing values of these columns with random number in normal range\n",
    "Note: but i can not find the unit and normal range for them so i drop them first >_<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stay_id                   0\n",
       "charttime                 0\n",
       "calcium                 933\n",
       "creatinine              261\n",
       "glucose                 444\n",
       "sodium                  214\n",
       "chloride                241\n",
       "hemoglobin             1179\n",
       "wbc                    1207\n",
       "alt                    3964\n",
       "ast                    3936\n",
       "alp                    3976\n",
       "bilirubin_total        3957\n",
       "pt                     3068\n",
       "liver_function_test       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use KNN to impute the rest\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors = 10)\n",
    "dynamic_data.iloc[:,2:] = imputer.fit_transform(dynamic_data.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define normal ranges for each column\n",
    "normal_ranges = {\n",
    "    'alt': (5, 40),\n",
    "    'ast': (10, 35),\n",
    "    'alp': (40, 130),\n",
    "    'bilirubin_total': (0.1, 1.0),\n",
    "    'pt': (9.5, 13.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dynamic_data['liver_function_test'] == False\n",
    "n_no_test = mask.sum()\n",
    "def sample_normal(col):\n",
    "    lower = normal_ranges[col][0]\n",
    "    upper = normal_ranges[col][1]\n",
    "    return np.random.normal(loc=(lower+upper)/2, scale=(upper-lower)/6, size=n_no_test)\n",
    "\n",
    "sampled_alt = sample_normal(\"alt\")\n",
    "sampled_ast = sample_normal(\"ast\")\n",
    "sampled_alp = sample_normal(\"alp\")\n",
    "sampled_bilirubin_total = sample_normal(\"bilirubin_total\")\n",
    "sampled_pt = sample_normal(\"pt\")\n",
    "dynamic_data.loc[mask, 'alt'] = sampled_alt\n",
    "dynamic_data.loc[mask, 'ast'] = sampled_ast\n",
    "dynamic_data.loc[mask, 'alp'] = sampled_alp\n",
    "dynamic_data.loc[mask, 'bilirubin_total'] = sampled_bilirubin_total\n",
    "dynamic_data.loc[mask, 'pt'] = sampled_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To address the issue that same patient has differrent results at the same charttime\n",
    "dynamic_data = dynamic_data.groupby(['stay_id','charttime']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the new dynamic_data into a csv file\n",
    "dynamic_data.to_csv('preprocessed_dynamic_data.csv', index=False)\n",
    "\n",
    "# Make a copy of the dynamic_data\n",
    "new_dynamic_data = dynamic_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      621\n",
       "2      648\n",
       "3      263\n",
       "4      102\n",
       "5       51\n",
       "6       40\n",
       "7       28\n",
       "8       22\n",
       "9       26\n",
       "10      19\n",
       "11      12\n",
       "12      10\n",
       "13       9\n",
       "14       4\n",
       "15       3\n",
       "16       3\n",
       "17       9\n",
       "18       3\n",
       "19       3\n",
       "20       5\n",
       "21       1\n",
       "22       4\n",
       "23       2\n",
       "24       2\n",
       "25       3\n",
       "26       1\n",
       "27       1\n",
       "28       8\n",
       "29       2\n",
       "30       1\n",
       "31       1\n",
       "33       2\n",
       "38       1\n",
       "39       1\n",
       "40       1\n",
       "41       2\n",
       "44       1\n",
       "45       1\n",
       "49       1\n",
       "61       1\n",
       "62       1\n",
       "82       1\n",
       "93       1\n",
       "131      1\n",
       "196      1\n",
       "Name: charttime, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of patients for each number of charttime\n",
    "# and print the data out in this format: number of charttime, number of patients\n",
    "new_dynamic_data.groupby('stay_id')['charttime'].count().value_counts().sort_index()\n",
    "\n",
    "# Print the number of charttimes for each patient\n",
    "# dynamic_data.groupby('stay_id')['charttime'].count()\n",
    "\n",
    "# Print the total number of unique patients\n",
    "# print('Total number of unique patients: ', dynamic_data['stay_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients with exactly 4 charttimes:  102\n",
      "Patients with less than 4 charttimes:  1532\n",
      "Patients with more than 4 charttimes:  289\n"
     ]
    }
   ],
   "source": [
    "# Look through the list and find the patients with exactly 4 charttimes\n",
    "print('Patients with exactly 4 charttimes: ', new_dynamic_data.groupby('stay_id')['charttime'].count().value_counts()[4])\n",
    "\n",
    "# Print the number of patients with less than 4 charttimes\n",
    "print('Patients with less than 4 charttimes: ', new_dynamic_data.groupby('stay_id')['charttime'].count().value_counts().loc[:3].sum())\n",
    "\n",
    "# Print the number of patients with more than 4 charttimes\n",
    "print('Patients with more than 4 charttimes: ', new_dynamic_data.groupby('stay_id')['charttime'].count().value_counts().loc[5:].sum())\n",
    "\n",
    "# Create two empty lists: one for patients with less than 4 charttimes and one for patients with more than 4 charttimes\n",
    "stay_id_less_than_4 = []\n",
    "stay_id_more_than_4 = []\n",
    "\n",
    "# Loop through dynamic_data\n",
    "for stay_id, group in new_dynamic_data.groupby('stay_id'):\n",
    "    # If a stay_id has less than 4 charttimes, append the stay_id to stay_id_less_than_4\n",
    "    if len(group) < 4:\n",
    "        stay_id_less_than_4.append(stay_id)\n",
    "    # Else if a stay_id has more than 4 charttimes, append the stay_id to stay_id_more_than_4\n",
    "    elif len(group) > 4:\n",
    "        stay_id_more_than_4.append(stay_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of charttime counts less than 4:  3\n",
      "Number of charttimes counts greater than 4:  41\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[-1], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[-1], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[-1], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358063/1164677254.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients with 4 charttimes:  102\n"
     ]
    }
   ],
   "source": [
    "# For patients with less than 4 charttimes, pad the data with the last charttime to make sure each patient has 4 charttimes\n",
    "# For patients with more than 4 charttimes, use the sliding window method to get 4 charttimes\n",
    "\n",
    "# Get the list of charttimes less than 4\n",
    "less_than_4 = new_dynamic_data.groupby('stay_id')['charttime'].count().value_counts().sort_index().index[:3]\n",
    "print('Number of charttime counts less than 4: ', len(less_than_4))\n",
    "\n",
    "# Get the list charttime counts greater than 4\n",
    "more_than_4 = new_dynamic_data.groupby('stay_id')['charttime'].count().value_counts().sort_index().index[4:]\n",
    "print('Number of charttimes counts greater than 4: ', len(more_than_4))\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Use the last charttime to pad the data for patients with less than 4 charttimes\n",
    "for i in less_than_4:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    mask = new_dynamic_data.groupby('stay_id')['charttime'].count() == i\n",
    "    # pad the data for each patient stay_id\n",
    "    for j in stay_id_less_than_4:\n",
    "        for k in range(4-i):\n",
    "            new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[-1], ignore_index=True)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# # Use the sliding window method to get 4 charttimes\n",
    "# # Only use the 4 charttimes obtained from the sliding window method for each patient with more than 4 charttimes\n",
    "# # Drop the rest of the charttimes for each patient with more than 4 charttimes\n",
    "# for i in more_than_4:\n",
    "#     count += 1\n",
    "#     print(count)\n",
    "#     mask = new_dynamic_data.groupby('stay_id')['charttime'].count() == i\n",
    "#     # For each patient stay_id, use the sliding window method to get 4 charttimes\n",
    "#     # Add these 4 charttimes to new_dynamic_data\n",
    "#     # Drop the original charttimes for each patient stay_id\n",
    "#     for j in stay_id_more_than_4:\n",
    "#         for k in range(i-3):\n",
    "#             new_dynamic_data = new_dynamic_data.append(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].iloc[k:k+4], ignore_index=True)\n",
    "#         new_dynamic_data = new_dynamic_data.drop(new_dynamic_data.loc[new_dynamic_data['stay_id'] == j].index)\n",
    "\n",
    "\n",
    "# Check if the number of patients with 4 charttimes is equal to the total number of patients\n",
    "print('Number of patients with 4 charttimes: ', new_dynamic_data.groupby('stay_id')['charttime'].count().value_counts()[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    102\n",
       "7    621\n",
       "8    648\n",
       "9    263\n",
       "Name: charttime, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of patients for each number of charttime\n",
    "# and print the data out in this format: number of charttime, number of patients\n",
    "new_dynamic_data.groupby('stay_id')['charttime'].count().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load static_data\n",
    "static_data = pd.read_csv('data/static_data.csv')\n",
    "\n",
    "# Merge static_data and dynamic_data\n",
    "merged_data = pd.merge(static_data, dynamic_data, on='stay_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a time-series classification model using LSTM RNN + Single Layer Perceptron (SLP) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Import keras and tensorflow\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import keras and tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define timesteps and the number of features\n",
    "n_timesteps = 8\n",
    "n_features = 7\n",
    "\n",
    "# RNN + MLP Model\n",
    "\n",
    "# Define input layer\n",
    "recurrent_input = Input(shape=(n_timesteps,n_features),name=TIMESERIES_INPUT)\n",
    "static_input = Input(shape=(x_train_over_static.shape[1], ),name=STATIC_INPUT)\n",
    "\n",
    "# RNN Layers\n",
    "# layer - 1\n",
    "rec_layer_one = Bidirectional(LSTM(128, \n",
    "                              kernel_regularizer=l2(0.01),\n",
    "                              recurrent_regularizer=l2(0.01),\n",
    "                              return_sequences=True),\n",
    "                              name=BIDIRECTIONAL_LAYER_1)(recurrent_input)\n",
    "rec_layer_one = Dropout(0.1,name=DROPOUT_LAYER_1)(rec_layer_one)\n",
    "\n",
    "# layer - 2\n",
    "rec_layer_two = Bidirectional(LSTM(64, \n",
    "                              kernel_regularizer=l2(0.01),\n",
    "                              recurrent_regularizer=l2(0.01)),\n",
    "                              name =BIDIRECTIONAL_LAYER_2)(rec_layer_one)\n",
    "rec_layer_two = Dropout(0.1,name=DROPOUT_LAYER_2)(rec_layer_two)\n",
    "\n",
    "# SLP Layers\n",
    "static_layer_one = Dense(64, kernel_regularizer=l2(0.001), activation='relu',name=DENSE_LAYER_1)(static_input)\n",
    "\n",
    "# Combine layers - RNN + MLP\n",
    "combined = Concatenate(axis= 1, name=CONCATENATED_TIMESERIES_STATIC)([rec_layer_two, static_layer_one])\n",
    "combined_dense_two = Dense(64, activation='relu', name=DENSE_LAYER_2)(combined)\n",
    "output = Dense(n_outputs, activation='sigmoid', name=OUTPUT_LAYER)(combined_dense_two)\n",
    "\n",
    "# Compile Model\n",
    "model = Model(inputs=[recurrent_input,static_input],outputs=[output])\n",
    "\n",
    "# binary cross entropy loss\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "# focal loss\n",
    "def focal_loss_custom(alpha, gamma):\n",
    "    def binary_focal_loss(y_true, y_pred):\n",
    "\n",
    "        fl = tfa.losses.SigmoidFocalCrossEntropy(alpha=alpha, gamma=gamma)\n",
    "\n",
    "        y_true_K = K.ones_like(y_true)\n",
    "\n",
    "        focal_loss = fl(y_true, y_pred)\n",
    "\n",
    "        return focal_loss\n",
    "return binary_focal_loss\n",
    "\n",
    "model.compile(loss=focal_loss_custom(alpha=0.2, gamma=2.0), optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics for evaluating the model - recall, precision and f1-score\n",
    "def recall_m(y_true, y_pred):\n",
    "   true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "   possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "   recall = true_positives / (possible_positives + K.epsilon())\n",
    "   return recall\n",
    "def precision_m(y_true, y_pred):\n",
    "   true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "   predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "   precision = true_positives / (predicted_positives + K.epsilon())\n",
    "   return precision\n",
    "def f1_m(y_true, y_pred):\n",
    "   precision = precision_m(y_true, y_pred)\n",
    "   recall = recall_m(y_true, y_pred)\n",
    "   return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "history =  model.fit([np.asarray(x_train_reshape).astype('float32'), np.asarray(x_train_over_static).astype('float32')],\n",
    "                     y_train_reshape, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data=([np.asarray(x_val_reshape).astype('float32'), np.asarray(x_val_static).astype('float32')],y_val_reshape))\n",
    "# summarize history for accuracy\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper left')\n",
    "pyplot.show()\n",
    "# summarize history for loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper left')\n",
    "pyplot.show()\n",
    "#evaluate model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate([np.asarray(x_test_reshape).astype('float32'),np.asarray(x_test_static).astype('float32')], y_test_reshape, batch_size=batch_size, verbose=0)\n",
    "#print output\n",
    "print(\"Accuracy:{} , F1_Score:{}, Precision:{}, Recall:{}\".format(accuracy, f1_score, precision, recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me5413",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f869599479e8de64e113663a67291a816457c71281cb93a123bd203dbc6e9356"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
