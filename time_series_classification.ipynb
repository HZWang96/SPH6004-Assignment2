{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>total_protein</th>\n",
       "      <th>calcium</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>sodium</th>\n",
       "      <th>chloride</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>...</th>\n",
       "      <th>ph</th>\n",
       "      <th>lactate</th>\n",
       "      <th>pt</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>sofa_respiration</th>\n",
       "      <th>sofa_coagulation</th>\n",
       "      <th>sofa_liver</th>\n",
       "      <th>sofa_cardiovascular</th>\n",
       "      <th>sofa_cns</th>\n",
       "      <th>sofa_renal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35715575</td>\n",
       "      <td>2148-12-27 18:15:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>137.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34483718</td>\n",
       "      <td>2118-01-04 03:58:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>129.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31826892</td>\n",
       "      <td>2163-03-10 19:59:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36154799</td>\n",
       "      <td>2131-12-02 19:14:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32732521</td>\n",
       "      <td>2116-08-12 12:45:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stay_id                charttime  total_protein  calcium  creatinine  \\\n",
       "0  35715575  2148-12-27 18:15:00.000            NaN      8.5         0.9   \n",
       "1  34483718  2118-01-04 03:58:00.000            NaN      8.2         0.8   \n",
       "2  31826892  2163-03-10 19:59:00.000            NaN      7.7         0.4   \n",
       "3  36154799  2131-12-02 19:14:00.000            NaN      NaN         NaN   \n",
       "4  32732521  2116-08-12 12:45:00.000            NaN      NaN         4.0   \n",
       "\n",
       "   glucose  sodium  chloride  heart_rate  sbp  ...  ph  lactate    pt  \\\n",
       "0    137.0   138.0     104.0         NaN  NaN  ... NaN      NaN   NaN   \n",
       "1    129.0   141.0     101.0         NaN  NaN  ... NaN      NaN  12.1   \n",
       "2    112.0   136.0      98.0         NaN  NaN  ... NaN      NaN   NaN   \n",
       "3      NaN     NaN       NaN         NaN  NaN  ... NaN      NaN   NaN   \n",
       "4    135.0   139.0     105.0         NaN  NaN  ... NaN      NaN   NaN   \n",
       "\n",
       "   urineoutput  sofa_respiration  sofa_coagulation  sofa_liver  \\\n",
       "0          NaN               NaN               NaN         NaN   \n",
       "1          NaN               NaN               NaN         NaN   \n",
       "2          NaN               NaN               NaN         NaN   \n",
       "3          NaN               NaN               NaN         NaN   \n",
       "4          NaN               NaN               NaN         NaN   \n",
       "\n",
       "   sofa_cardiovascular  sofa_cns  sofa_renal  \n",
       "0                  NaN       NaN         NaN  \n",
       "1                  NaN       NaN         NaN  \n",
       "2                  NaN       NaN         NaN  \n",
       "3                  NaN       NaN         NaN  \n",
       "4                  NaN       NaN         NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sph_dynamic.csv into a Pandas dataframe and display the first 5 rows of the data\n",
    "dynamic_data = pd.read_csv('sph_dynamic.csv')\n",
    "dynamic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stay_id                   0\n",
       "charttime                 0\n",
       "total_protein          6930\n",
       "calcium                 933\n",
       "creatinine              261\n",
       "glucose                 444\n",
       "sodium                  214\n",
       "chloride                241\n",
       "heart_rate             6833\n",
       "sbp                    6895\n",
       "dbp                    6895\n",
       "mbp                    6887\n",
       "resp_rate              6832\n",
       "temperature            6974\n",
       "hemoglobin             1179\n",
       "wbc                    1207\n",
       "alt                    3964\n",
       "ast                    3936\n",
       "alp                    3976\n",
       "bilirubin_total        3957\n",
       "bilirubin_direct       6808\n",
       "bilirubin_indirect     6812\n",
       "ph                     7004\n",
       "lactate                7012\n",
       "pt                     3068\n",
       "urineoutput            6942\n",
       "sofa_respiration       7005\n",
       "sofa_coagulation       7023\n",
       "sofa_liver             7023\n",
       "sofa_cardiovascular    6872\n",
       "sofa_cns               6979\n",
       "sofa_renal             7024\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of missing values in each column of the dynamic_data\n",
    "dynamic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns in dynamic_data with more than 80% of the values\n",
    "for col in dynamic_data.columns:\n",
    "    if dynamic_data[col].isnull().sum() > len(dynamic_data)*0.8:\n",
    "        del dynamic_data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stay_id               0\n",
       "charttime             0\n",
       "calcium             933\n",
       "creatinine          261\n",
       "glucose             444\n",
       "sodium              214\n",
       "chloride            241\n",
       "hemoglobin         1179\n",
       "wbc                1207\n",
       "alt                3964\n",
       "ast                3936\n",
       "alp                3976\n",
       "bilirubin_total    3957\n",
       "pt                 3068\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of missing values in each column of the dynamic_data\n",
    "dynamic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144030/240455136.py:15: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  dynamic_data = dynamic_data.groupby('stay_id').apply(liver_categorize)\n"
     ]
    }
   ],
   "source": [
    "# ['alt','ast','alp','bilirubin_total','pt'] are liver function related test results\n",
    "# create a new binary column 'liver_function_test', True/1 means have ever taken liver function test\n",
    "liver_test_result = ['alt','ast','alp','bilirubin_total','pt']\n",
    "def liver_categorize(group):\n",
    "    flag = True\n",
    "    for i in liver_test_result:\n",
    "        if group[i].notnull().any():\n",
    "            flag = False\n",
    "    if flag:\n",
    "        group['liver_function_test'] = False\n",
    "    else:\n",
    "        group['liver_function_test'] = True\n",
    "    return group\n",
    "\n",
    "dynamic_data = dynamic_data.groupby('stay_id').apply(liver_categorize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that patients with no relevant results recorded do not have liver issues, we impute these patients' missing values of these columns with random number in normal range\n",
    "Note: but i can not find the unit and normal range for them so i drop them first >_<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stay_id                   0\n",
       "charttime                 0\n",
       "calcium                 933\n",
       "creatinine              261\n",
       "glucose                 444\n",
       "sodium                  214\n",
       "chloride                241\n",
       "hemoglobin             1179\n",
       "wbc                    1207\n",
       "alt                    3964\n",
       "ast                    3936\n",
       "alp                    3976\n",
       "bilirubin_total        3957\n",
       "pt                     3068\n",
       "liver_function_test       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use KNN to impute the rest\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors = 10)\n",
    "dynamic_data.iloc[:,2:] = imputer.fit_transform(dynamic_data.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define normal ranges for each column\n",
    "normal_ranges = {\n",
    "    'alt': (5, 40),\n",
    "    'ast': (10, 35),\n",
    "    'alp': (40, 130),\n",
    "    'bilirubin_total': (0.1, 1.0),\n",
    "    'pt': (9.5, 13.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dynamic_data['liver_function_test'] == False\n",
    "n_no_test = mask.sum()\n",
    "def sample_normal(col):\n",
    "    lower = normal_ranges[col][0]\n",
    "    upper = normal_ranges[col][1]\n",
    "    return np.random.normal(loc=(lower+upper)/2, scale=(upper-lower)/6, size=n_no_test)\n",
    "\n",
    "sampled_alt = sample_normal(\"alt\")\n",
    "sampled_ast = sample_normal(\"ast\")\n",
    "sampled_alp = sample_normal(\"alp\")\n",
    "sampled_bilirubin_total = sample_normal(\"bilirubin_total\")\n",
    "sampled_pt = sample_normal(\"pt\")\n",
    "dynamic_data.loc[mask, 'alt'] = sampled_alt\n",
    "dynamic_data.loc[mask, 'ast'] = sampled_ast\n",
    "dynamic_data.loc[mask, 'alp'] = sampled_alp\n",
    "dynamic_data.loc[mask, 'bilirubin_total'] = sampled_bilirubin_total\n",
    "dynamic_data.loc[mask, 'pt'] = sampled_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To address the issue that same patient has differrent results at the same charttime\n",
    "dynamic_data = dynamic_data.groupby(['stay_id','charttime']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      648\n",
       "1      621\n",
       "3      263\n",
       "4      102\n",
       "5       51\n",
       "6       40\n",
       "7       28\n",
       "9       26\n",
       "8       22\n",
       "10      19\n",
       "11      12\n",
       "12      10\n",
       "17       9\n",
       "13       9\n",
       "28       8\n",
       "20       5\n",
       "14       4\n",
       "22       4\n",
       "16       3\n",
       "15       3\n",
       "18       3\n",
       "19       3\n",
       "25       3\n",
       "29       2\n",
       "23       2\n",
       "24       2\n",
       "33       2\n",
       "41       2\n",
       "26       1\n",
       "30       1\n",
       "31       1\n",
       "40       1\n",
       "44       1\n",
       "62       1\n",
       "196      1\n",
       "49       1\n",
       "82       1\n",
       "27       1\n",
       "93       1\n",
       "131      1\n",
       "39       1\n",
       "21       1\n",
       "45       1\n",
       "38       1\n",
       "61       1\n",
       "Name: charttime, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the number of patients for each number of charttime\n",
    "dynamic_data.groupby('stay_id')['charttime'].count().value_counts()\n",
    "\n",
    "# Print the number of charttimes for each patient\n",
    "# dynamic_data.groupby('stay_id')['charttime'].count()\n",
    "\n",
    "# Print the totoal number of unique patients\n",
    "# print('Total number of unique patients: ', dynamic_data['stay_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients with exactly 8 charttimes:  621\n"
     ]
    }
   ],
   "source": [
    "# Look through the list and find the patients with exactly 2 charttimes\n",
    "print('Patients with exactly 8 charttimes: ', dynamic_data.groupby('stay_id')['charttime'].count().value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the new dynamic_data into a csv file\n",
    "dynamic_data.to_csv('preprocessed_dynamic_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a time-series classification model using LSTM RNN + Single Layer Perceptron (SLP) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Import keras and tensorflow\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import keras and tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define timesteps and the number of features\n",
    "n_timesteps = 8\n",
    "n_features = 7\n",
    "\n",
    "# RNN + MLP Model\n",
    "\n",
    "# Define input layer\n",
    "recurrent_input = Input(shape=(n_timesteps,n_features),name=TIMESERIES_INPUT)\n",
    "static_input = Input(shape=(x_train_over_static.shape[1], ),name=STATIC_INPUT)\n",
    "\n",
    "# RNN Layers\n",
    "# layer - 1\n",
    "rec_layer_one = Bidirectional(LSTM(128, \n",
    "                              kernel_regularizer=l2(0.01),\n",
    "                              recurrent_regularizer=l2(0.01),\n",
    "                              return_sequences=True),\n",
    "                              name=BIDIRECTIONAL_LAYER_1)(recurrent_input)\n",
    "rec_layer_one = Dropout(0.1,name=DROPOUT_LAYER_1)(rec_layer_one)\n",
    "\n",
    "# layer - 2\n",
    "rec_layer_two = Bidirectional(LSTM(64, \n",
    "                              kernel_regularizer=l2(0.01),\n",
    "                              recurrent_regularizer=l2(0.01)),\n",
    "                              name =BIDIRECTIONAL_LAYER_2)(rec_layer_one)\n",
    "rec_layer_two = Dropout(0.1,name=DROPOUT_LAYER_2)(rec_layer_two)\n",
    "\n",
    "# SLP Layers\n",
    "static_layer_one = Dense(64, kernel_regularizer=l2(0.001), activation='relu',name=DENSE_LAYER_1)(static_input)\n",
    "\n",
    "# Combine layers - RNN + MLP\n",
    "combined = Concatenate(axis= 1, name=CONCATENATED_TIMESERIES_STATIC)([rec_layer_two, static_layer_one])\n",
    "combined_dense_two = Dense(64, activation='relu', name=DENSE_LAYER_2)(combined)\n",
    "output = Dense(n_outputs, activation='sigmoid', name=OUTPUT_LAYER)(combined_dense_two)\n",
    "\n",
    "# Compile Model\n",
    "model = Model(inputs=[recurrent_input,static_input],outputs=[output])\n",
    "\n",
    "# binary cross entropy loss\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "# focal loss\n",
    "def focal_loss_custom(alpha, gamma):\n",
    "    def binary_focal_loss(y_true, y_pred):\n",
    "\n",
    "        fl = tfa.losses.SigmoidFocalCrossEntropy(alpha=alpha, gamma=gamma)\n",
    "\n",
    "        y_true_K = K.ones_like(y_true)\n",
    "\n",
    "        focal_loss = fl(y_true, y_pred)\n",
    "\n",
    "        return focal_loss\n",
    "return binary_focal_loss\n",
    "\n",
    "model.compile(loss=focal_loss_custom(alpha=0.2, gamma=2.0), optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics for evaluating the model - recall, precision and f1-score\n",
    "def recall_m(y_true, y_pred):\n",
    "   true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "   possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "   recall = true_positives / (possible_positives + K.epsilon())\n",
    "   return recall\n",
    "def precision_m(y_true, y_pred):\n",
    "   true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "   predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "   precision = true_positives / (predicted_positives + K.epsilon())\n",
    "   return precision\n",
    "def f1_m(y_true, y_pred):\n",
    "   precision = precision_m(y_true, y_pred)\n",
    "   recall = recall_m(y_true, y_pred)\n",
    "   return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "history =  model.fit([np.asarray(x_train_reshape).astype('float32'), np.asarray(x_train_over_static).astype('float32')],\n",
    "                     y_train_reshape, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data=([np.asarray(x_val_reshape).astype('float32'), np.asarray(x_val_static).astype('float32')],y_val_reshape))\n",
    "# summarize history for accuracy\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper left')\n",
    "pyplot.show()\n",
    "# summarize history for loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper left')\n",
    "pyplot.show()\n",
    "#evaluate model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate([np.asarray(x_test_reshape).astype('float32'),np.asarray(x_test_static).astype('float32')], y_test_reshape, batch_size=batch_size, verbose=0)\n",
    "#print output\n",
    "print(\"Accuracy:{} , F1_Score:{}, Precision:{}, Recall:{}\".format(accuracy, f1_score, precision, recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me5413",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f869599479e8de64e113663a67291a816457c71281cb93a123bd203dbc6e9356"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
